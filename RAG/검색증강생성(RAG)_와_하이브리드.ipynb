{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEZ-bRegbP-_",
        "outputId": "020b0397-8e7a-4388-a09d-49559bb40a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5vLrZx4cY7E"
      },
      "source": [
        "# 1. Dense Vector Search (밀집 벡터 검색)\n",
        "\n",
        "\n",
        "$$\n",
        "\\text{similarity}(q, d) = \\cos(\\theta)\n",
        "= \\frac{q \\cdot d}{\\|q\\| \\times \\|d\\|}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vr2mN5tkIZW"
      },
      "source": [
        "- 원리 : 문장을 고차원 벡터로 변환하고 코사인 유사도를 이용해서 의미적 유사성 측정\n",
        "- 장점\n",
        "  - 의미적 유사성 포착(동의어)\n",
        "  - 비가온다 <->장마가 시작됐다\n",
        "- 단점\n",
        "  - 고유명사, 숫자 등 정확한 매칭에 약해"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4h3o-731cwrt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5RiBv-mbuJo"
      },
      "source": [
        "# 2. BM25 (Best Match 25)\n",
        "  - 키워드 기반 희소 검색\n",
        "\n",
        "$$\n",
        "\\text{BM25}(D, Q) = \\sum_{q_i \\in Q} \\text{IDF}(q_i) \\cdot\n",
        "\\frac{f(q_i, D)(k_1 + 1)}\n",
        "{f(q_i, D) + k_1\\left(1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}}\\right)}\n",
        "$$\n",
        "\n",
        "\n",
        "**IDF(qᵢ)**: 단어 qᵢ의 역문서 빈도 (드문 단어일수록 값이 큼)  \n",
        "**f(qᵢ, D)**: 문서 D에서 단어 qᵢ가 등장한 횟수  \n",
        "**k₁**: 포화 파라미터 (일반적으로 1.2 ~ 2.0)  \n",
        "**b**: 문서 길이 정규화 파라미터 (일반적으로 0.75)  \n",
        "**avgdl**: 전체 문서들의 평균 길이\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciwveinek5GR"
      },
      "source": [
        "- TF-IDF 개선버전, 문서 내 단어 빈도와 희소성을 고려\n",
        "- 장점\n",
        "  - 정확한 키워드 매칭\n",
        "  - 고유명사 검색에 강함\n",
        "- 단점\n",
        "  - 의미적 유사성 포착 불가\n",
        "  - 비<->장마 연결 어려움  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0HmwgjXEk4tC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAAwsnD5cfJr"
      },
      "source": [
        "# 3. Reciprocal Rank Fusion (RRF)\n",
        "\n",
        "$$\n",
        "\\text{RRF}(d) = \\sum_i \\frac{1}{k + \\text{rank}_i(d)}\n",
        "$$\n",
        "\n",
        "**d**: 문서  \n",
        "**k**: 상수 (일반적으로 60 사용)  \n",
        "**rankᵢ(d)**: i번째 검색 시스템에서 문서 d가 받은 순위\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWQTSQm8lVqi"
      },
      "source": [
        "- 여러검색 결과의 순위를 통합하여 최종 랭킹을 생성\n",
        "- 장점\n",
        "  - 다양한 검색 방식의 장점 결합\n",
        "  - 점수 스케일이 다른 검색 결과도 통합 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "yFIfAwyybu1e"
      },
      "outputs": [],
      "source": [
        "# 문장 임베딩으로 벡터 검색\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqHnwq9imXRZ",
        "outputId": "bc1a15dc-6777-46bd-cf21-356eb1e89c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검색결과\n",
            " 1. 프린스턴 대학교 AI 연구소 ( 거리 : 226.3636 ) 인덱스 : [2 0 1]\n",
            " 2. 로버트 헨리 딕이 1946년에 연구했다 ( 거리 : 388.5460 ) 인덱스 : [2 0 1]\n",
            " 3. 2023년 AI 기술이 발전했다 ( 거리 : 698.7937 ) 인덱스 : [2 0 1]\n"
          ]
        }
      ],
      "source": [
        "# 한국어 임베딩 모델 로드\n",
        "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
        "# sample doc\n",
        "documents = [\"로버트 헨리 딕이 1946년에 연구했다\", \"2023년 AI 기술이 발전했다\", \"프린스턴 대학교 AI 연구소\"]\n",
        "# 문서 임베딩\n",
        "doc_embeddings = model.encode(documents)\n",
        "\n",
        "# FAISS 인덱스 생성\n",
        "dimension =  doc_embeddings.shape[1]   #(3, 768)\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(doc_embeddings.astype('float32'))\n",
        "\n",
        "# 쿼리 검색\n",
        "query = '프린스턴 대학의 연구소'\n",
        "query_embedding =  model.encode([query])\n",
        "distance, indices =  index.search( query_embedding.astype('float32'), k=3)\n",
        "print('검색결과')\n",
        "for i, (dist,idx) in  enumerate( zip(distance[0], indices[0]) ):\n",
        "  print(f' {i+1}. {documents[idx]} ( 거리 : {dist:.4f} ) 인덱스 : {indices[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WogNHKdEr2Wz"
      },
      "source": [
        "BM25 검색 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "mYdWjDVApAp1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "from transformers import AutoTokenizer\n",
        "class SimpleBM25:\n",
        "  def __init__(self, documents, k1=1.2, b=0.75):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
        "    self.k1 = k1\n",
        "    self.b  = b\n",
        "    self.documents = documents\n",
        "    self.tokenized_docs = [ self.tokenizer.tokenize(doc) for doc in documents ]\n",
        "    self.avg_doc_len = sum(len(d)  for d in self.tokenized_docs) / len(self.tokenized_docs)\n",
        "    self.idf = self._compute_idf()\n",
        "  def _compute_idf(self):\n",
        "    idf = defaultdict(float)\n",
        "    N = len(self.tokenized_docs)\n",
        "    # TF 각 단어의 문서 빈도 계산\n",
        "    tf = defaultdict(int)\n",
        "    for doc in self.tokenized_docs:\n",
        "      for token in set(doc):\n",
        "        tf[token] += 1\n",
        "    # IDF 계산\n",
        "    for token,freq in tf.items():\n",
        "      # 비율이 클수록(드문 토큰일수록) 값이 커지며, 흔한 토큰일 수록 작아진\n",
        "      idf[token] = math.log((N - freq + 0.5) / (freq + 0.5)+1 )  # 토큰이 나타나지 않은 문서수  , 토큰이 등장한 문서수\n",
        "    return idf\n",
        "  def score(self, query):\n",
        "    query_tokens =  self.tokenizer.tokenize(query)\n",
        "    scores = []\n",
        "    for doc in self.tokenized_docs:\n",
        "      score = 0\n",
        "      doc_len = len(doc)\n",
        "      # 단어 빈도 계산\n",
        "      tf = defaultdict(int)\n",
        "      for token in doc:\n",
        "        tf[token] += 1\n",
        "      for token in query_tokens:\n",
        "        if token in tf:\n",
        "          freq = tf[token]\n",
        "          numerator = self.idf[token] * freq + (self.k1 + 1)\n",
        "          denoinator = freq + self.k1 * (1 - self.b + self.b*doc_len / self.avg_doc_len)\n",
        "          score += numerator / denoinator\n",
        "      scores.append(score)\n",
        "    return scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqI6KeBVtTW0",
        "outputId": "72447c5c-38e3-46f0-9579-b76a5152ff04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bm25 점수 : [0, 0, 5.057078766308966]\n"
          ]
        }
      ],
      "source": [
        "# 사용\n",
        "documents = [\"로버트 헨리 딕이 1946년에 연구했다\", \"2023년 AI 기술이 발전했다\", \"프린스턴 대학교 AI 연구소\"]\n",
        "bm25 = SimpleBM25(documents)\n",
        "query = '프린스턴 대학의 연구소'\n",
        "scores = bm25.score(query)\n",
        "print(f'bm25 점수 : {scores}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lHTaUwwxvpk"
      },
      "source": [
        "하이브리드 검색 : 밀집벡터 + bm25 -> rank\n",
        "  - 여러 검색결과의 순위를 RRF로 통합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "5xrkdvZRxn0k"
      },
      "outputs": [],
      "source": [
        "def reciprocal_rank_fusion(rankings, k=60):\n",
        "  '''\n",
        "  여러 검색결과의 순위를 RRf로 통합\n",
        "  Args:\n",
        "    rankings : 각 검색방식의 문서 인덱스 순위 리스트\n",
        "    k: 상수\n",
        "  Return:\n",
        "    통합 점수로 정렬된(문서인덱스, 점수) 리스트\n",
        "  '''\n",
        "  print(f'rankings : {rankings}')\n",
        "  rrf_scores = defaultdict(float)\n",
        "  for ranking in rankings:   # rankings : [array([2, 0, 1]), array([2, 1, 0])]\n",
        "    for rank, doc_id in enumerate(ranking, 1):\n",
        "      rrf_scores[doc_id] += 1.0 / (k + rank)\n",
        "  return sorted(rrf_scores.items(), key = lambda x : x[1], reverse=True)\n",
        "\n",
        "def hybrid_search(query,dense_index, documents, bm25, top_k=3 ,rrf_k=60):\n",
        "  # Dense Search FAISS\n",
        "  query_embedding = model.encode([query])\n",
        "  D,I =  dense_index.search(query_embedding.astype('float32'), k=top_k)\n",
        "  desnse_ranking = np.array(I[0])\n",
        "  print(f'desnse_ranking : {desnse_ranking}')\n",
        "\n",
        "  # BM25\n",
        "  sparse_scores =  bm25.score(query)\n",
        "  sparse_ranking = np.array(np.argsort(sparse_scores)[::-1][:top_k] )\n",
        "  print(f'sparse_ranking : {sparse_ranking}')\n",
        "\n",
        "  # RRF 통합\n",
        "  results = reciprocal_rank_fusion([desnse_ranking,sparse_ranking], k=rrf_k)\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "earRDeGyyv3C",
        "outputId": "981b73f3-453e-45c8-8f59-e8ac89916251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "desnse_ranking : [1 2 0]\n",
            "sparse_ranking : [1 2 0]\n",
            "rankings : [array([1, 2, 0]), array([1, 2, 0])]\n",
            "하이브리드 검색 결과\n",
            "1. 2023년 AI 기술이 발전했다 (점수 : 0.0328)\n",
            "2. 프린스턴 대학교 AI 연구소 (점수 : 0.0323)\n",
            "3. 로버트 헨리 딕이 1946년에 연구했다 (점수 : 0.0317)\n"
          ]
        }
      ],
      "source": [
        "documents = [\"로버트 헨리 딕이 1946년에 연구했다\", \"2023년 AI 기술이 발전했다\", \"프린스턴 대학교 AI 연구소\"]\n",
        "# 한국어 SBERT 모델\n",
        "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
        "doc_embeddings = model.encode(documents).astype('float32')\n",
        "dimension = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "bms25 = SimpleBM25(documents)\n",
        "\n",
        "# 하이브리드 검색\n",
        "query = '기술발전'\n",
        "results = hybrid_search(query, index, documents,bm25,top_k=3)\n",
        "\n",
        "print(f'하이브리드 검색 결과')\n",
        "for rank, (doc_id, score) in enumerate(results, 1):\n",
        "  try:\n",
        "    print(f'{rank}. {documents[doc_id]} (점수 : {score:.4f})')\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "# desnse_ranking : [2 0 1]   2번문서가 1위\n",
        "# sparse_ranking : [2 1 0]   2번 문서가 1위"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geGXk9dv7KgD",
        "outputId": "4037d769-3cda-4ea5-f6b2-bc6cb3931f23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(np.int64(1), 0.03252247488101534),\n",
              " (np.int64(2), 0.032266458495966696),\n",
              " (np.int64(0), 0.03200204813108039)]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "xsAQ-f2877tl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
