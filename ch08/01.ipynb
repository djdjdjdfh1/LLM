{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5505ea06",
   "metadata": {},
   "source": [
    "### ìì—°ì–´ ê°ì •ë¶„ì„\n",
    "- ê°ì„±ì‚¬ì „ ê¸°ë°˜ : ë¯¸ë¦¬ì •ì˜ëœ ê°ì„± ë‹¨ì–´ ì‚¬ì „ ì‚¬ìš©(ê·œì¹™ ê¸°ë°˜)\n",
    "    - TextBlob, AFINN, VADER\n",
    "- ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ : ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ í•™ìŠµ(í†µê³„ ê¸°ë°˜)\n",
    "    - TF-IDF ë²¡í„°í™”\n",
    "    - ì„ í˜•íšŒê·€\n",
    "    - ë¡œì§€ìŠ¤í‹±íšŒê·€\n",
    "    - F1 Score, Recision, Recall -> classification report\n",
    "\n",
    "### ì‚¬ìš© ë°ì´í„°\n",
    "- NLTK ì˜í™” ë¦¬ë·°(2000ê°œ)\n",
    "- ë‹¤ìŒì˜í™”ë¦¬ë·°\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5267c8b",
   "metadata": {},
   "source": [
    "### ì•Œê³ ë¦¬ì¦˜\n",
    "- TextBlob  ì‚¬ì „ê¸°ë°˜ ê°ì„±ë¶„ì„\n",
    "- AFINN     ê°ì • ì ìˆ˜ ë§¤í•‘\n",
    "- VADER(Valance Aware Dictionary) ì†Œì…œë¯¸ë””ì–´ ìµœì í™” ê°ì„±ë¶„ì„\n",
    "- TF-IDF    í…ìŠ¤íŠ¸ ë²¡í„°í™”\n",
    "- Multinomial Naive Bayes í™•ë¥  ê¸°ë°˜ ë¶„ë¥˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7bac53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob\n",
    "# ì´ ì˜í™”ëŠ” ì •ë§ ì¢‹ê³  ì¬ë¯¸ìˆë‹¤\n",
    "    # ì¢‹ë‹¤ +1(ê¸ì •)\n",
    "    # ì¬ë¯¸ìˆë‹¤ +1(ê¸ì •)\n",
    "    # +2 > 0 --> ê¸ì •(pos) ë¶„ë¥˜\n",
    "# Polarity(ê·¹ì„±ë„)  (ê¸ì •ë‹¨ì–´ìˆ˜ ê°œìˆ˜ - ë¶€ì •ë‹¨ì–´ ê°œìˆ˜) / ì „ì²´ ë‹¨ì–´ ê°œìˆ˜\n",
    "# -1.0 ~ +1.0\n",
    "# 0 ì¤‘ë¦½\n",
    "# Subjectivity(ì£¼ê´€ì„±)\n",
    "# 0.0 ~ 1.0\n",
    "# 0 : ê°ê´€ì   1 : ì£¼ê´€ì \n",
    "\n",
    "# ë¬¸ë§¥ ë¬´ì‹œí•˜ê³  ë‹¨ì–´ ê·¹ì„±ë§Œ ê³ ë ¤\n",
    "# ì´ ì˜í™”ëŠ” ë‚˜ì˜ì§€ ì•Šë‹¤ -> ë‚˜ì˜ë‹¤(-) ì•Šë‹¤(-) ë¡œ ì¸ì‹\n",
    "# ì¥ì  : ë¹ ë¥¸ ì†ë„, í•™ìŠµ ë¶ˆí•„ìš”\n",
    "# ì‚¬ìš© : ì‹¤ì‹œê°„ ê°ì„±ë¶„ì„, ìŠ¤íŠ¸ë¦¬ë°ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe9e06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2940728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"TextBlob is amazingly simple to use.\"), Sentence(\"What a wonderful library for NLP!\")]\n",
      "['TextBlob', 'is', 'amazingly', 'simple', 'to', 'use', 'What', 'a', 'wonderful', 'library', 'for', 'NLP']\n",
      "[('TextBlob', 'NNP'), ('is', 'VBZ'), ('amazingly', 'RB'), ('simple', 'JJ'), ('to', 'TO'), ('use', 'VB'), ('What', 'WP'), ('a', 'DT'), ('wonderful', 'JJ'), ('library', 'NN'), ('for', 'IN'), ('NLP', 'NNP')]\n",
      "['textblob', 'wonderful library', 'nlp']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sentiment(polarity=0.5, subjectivity=0.6785714285714286)\n",
      "polarity: 0.5\n",
      "subjectivity: 0.6785714285714286\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob, Word\n",
    "# import nltk\n",
    "# nltk.download('brown')\n",
    "\n",
    "text = \"TextBlob is amazingly simple to use. What a wonderful library for NLP!\"\n",
    "blob = TextBlob(text)\n",
    "print(blob.sentences)\n",
    "print(blob.words)\n",
    "print(blob.tags)\n",
    "print(blob.noun_phrases)\n",
    "print('-'*100)\n",
    "# ê°ì„±ë¶„ì„\n",
    "print(blob.sentiment)\n",
    "print(f'polarity: {blob.sentiment.polarity}')\n",
    "print(f'subjectivity: {blob.sentiment.subjectivity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4835a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFINN(Lexicon-Based)  ê°ì„±ì‚¬ì „\n",
    "# ê° ë‹¨ì–´ì˜ -5 ~ +5ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³  í•©ì‚°\n",
    "# ì´ ì˜í™”ëŠ” ì¢‹ì§€ë§Œ ì¢‹ì§€ ì•Šì€ ë¶€ë¶„ë„ ìˆë‹¤\n",
    "    # ì¢‹ë‹¤ +3 ì¢‹ë‹¤ +3 ë‚˜ì˜ë‹¤ -3 = +3 > 0 ê¸ì •\n",
    "# score = sum(word_sentiment_value)\n",
    "# ë¶„ë¥˜ê·œì¹™ score > 0 ê¸ì •   score < 0 ë¶€ì •\n",
    "# ì´ëª¨í‹°ì½˜ì§€ì›\n",
    "# ê°•ë„í‘œí˜„ ì¸ì‹ very, really ë“±\n",
    "\n",
    "# ê°•ì¡° ìˆ˜ì •ì(intensifiers)\n",
    "    # ë§¤ìš°ì¢‹ë‹¤ = 1.5 * (ì¢‹ë‹¤ì˜ ì ìˆ˜)\n",
    "\n",
    "# AFINN vs TextBlob\n",
    "# AFINN : ë” ì •í™•í•œ ì ìˆ˜ ë§¤í•‘\n",
    "# TextBlob : ë” ì¼ë°˜ì ì¸ ì ‘ê·¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9189c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77fb9bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 4.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "af = Afinn()\n",
    "text1 = \"TextBlob is amazingly simple to use.\"\n",
    "text2 = \"What a wonderful library for NLP!\"\n",
    "score1 = af.score(text1)\n",
    "score2 = af.score(text2)\n",
    "score1, score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43790b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER ì†Œì…œë¯¸ë””ì–´ í…ìŠ¤íŠ¸ì— ìµœì í™”\n",
    "# ì´ ì˜í™”ëŠ” ì •ë§ì •ë§ í›Œë¥­í•´!!!\n",
    "# í›Œë¥­í•˜ë‹¤ (ê¸°ë³¸) + 0.7  ì •ë§ì •ë§ (ê°•ì¡°) * 1.5 \n",
    "# !!! (ë¬¸ì¥ë¶€í˜¸ê°•ì¡°) * 1.2\n",
    "# 4ê°œì˜ ê°ì • ì§€ìˆ˜\n",
    "    # positive ê¸ì • í™•ë¥  0 ~ 1\n",
    "    # negative ë¶€ì • í™•ë¥ \n",
    "    # neutral ì¤‘ë¦½ í™•ë¥ \n",
    "    # compound ì¢…í•©ì ìˆ˜ -1 ~ 1\n",
    "# score = compound_score / sqrt(compound_score**2 + 0.0625)\n",
    "# score >= 0.05 ê¸ì •\n",
    "# score <= -0.05 ë¶€ì •\n",
    "# ê·¸ ì‚¬ì´ëŠ” ì¤‘ë¦½\n",
    "# ëŒ€ì†Œë¬¸ì êµ¬ë¶„ AMAZING amazing ë‹¤ë¥¸ ì ìˆ˜ ë¶€ì—¬\n",
    "# :) ê¸ì •   :( ë¶€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5ed68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b7f5d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì¥ : I love this product! It's absolutely amazing ğŸ˜\n",
      "ì ìˆ˜ : {'neg': 0.0, 'neu': 0.318, 'pos': 0.682, 'compound': 0.862}\n",
      "ë¬¸ì¥ : This is the worst movie I've ever seen...\n",
      "ì ìˆ˜ : {'neg': 0.369, 'neu': 0.631, 'pos': 0.0, 'compound': -0.6249}\n",
      "ë¬¸ì¥ : The food was okay, not great but not bad either.\n",
      "ì ìˆ˜ : {'neg': 0.149, 'neu': 0.487, 'pos': 0.364, 'compound': 0.4728}\n",
      "ë¬¸ì¥ : Iâ€™m REALLY happy with the results!!!\n",
      "ì ìˆ˜ : {'neg': 0.0, 'neu': 0.472, 'pos': 0.528, 'compound': 0.7651}\n",
      "ë¬¸ì¥ : Not good at all. Iâ€™m disappointed.\n",
      "ì ìˆ˜ : {'neg': 0.579, 'neu': 0.421, 'pos': 0.0, 'compound': -0.6711}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyer = SentimentIntensityAnalyzer()\n",
    "sentences = [\n",
    "    \"I love this product! It's absolutely amazing ğŸ˜\",\n",
    "    \"This is the worst movie I've ever seen...\",\n",
    "    \"The food was okay, not great but not bad either.\",\n",
    "    \"Iâ€™m REALLY happy with the results!!!\",\n",
    "    \"Not good at all. Iâ€™m disappointed.\",\n",
    "]\n",
    "for s in sentences:\n",
    "    scores = analyer.polarity_scores(s)\n",
    "    print(f'ë¬¸ì¥ : {s}')\n",
    "    print(f'ì ìˆ˜ : {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5a62a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from textblob import TextBlob\n",
    "from afinn import Afinn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# nltk ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
    "nltk.download('movie_reviews', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "# ì˜í™” ë¦¬ë·° ë°ì´í„° ë¡œë“œ\n",
    "fileids = movie_reviews.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f55d2183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50, 50)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids[:50] ] + \\\n",
    "    [movie_reviews.raw(fileid) for fileid in fileids[-50:] ]\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids[:50] ] + \\\n",
    "    [movie_reviews.categories(fileid)[0] for fileid in fileids[-50:] ]\n",
    "len(reviews), categories.count('pos'), categories.count('neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "477d2bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„ : 0.61\n"
     ]
    }
   ],
   "source": [
    "# 1. TextBlob\n",
    "def sentiment_textblob(docs):\n",
    "    return ['pos' if TextBlob(doc).sentiment.polarity > 0 else 'neg' for doc in docs ]\n",
    "predictions_textblob = sentiment_textblob(reviews)\n",
    "accuracy_textblob = accuracy_score(categories, predictions_textblob)\n",
    "print(f'ì •í™•ë„ : {accuracy_textblob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1fe178f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„ : 0.7\n"
     ]
    }
   ],
   "source": [
    "# 2. AFINN \n",
    "def sentiment_afinn(docs):\n",
    "    afn = Afinn(emoticons=True)\n",
    "    return [ 'pos' if afn.score(doc) > 0 else 'neg' for doc in docs ]\n",
    "predictions = sentiment_afinn(reviews)\n",
    "accuracy = accuracy_score(categories, predictions)\n",
    "print(f'ì •í™•ë„ : {accuracy:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d729ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„ : 0.6\n"
     ]
    }
   ],
   "source": [
    "# 3. VADER \n",
    "def sentiment_vader(docs):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    return [ 'pos' if analyzer.polarity_scores(doc)['compound'] > 0 else 'neg' for doc in docs ]\n",
    "predictions = sentiment_vader(reviews)\n",
    "accuracy = accuracy_score(categories, predictions)\n",
    "print(f'ì •í™•ë„ : {accuracy:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ê°ì„±ë¶„ì„\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecdae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ\n",
    "\n",
    "# ë² ì´ì¦ˆ ì •ë¦¬\n",
    "# \"ì¢‹ë‹¤\" ë‹¨ì–´ë¥¼ ë³¸í›„ ì´ ë¦¬ë·°ê°€ ê¸ì •ì¼ í™•ë¥ \n",
    "# p(ê¸ì • | 'ì¢‹ë‹¤') = p('ì¢‹ë‹¤' | ê¸ì •) * p(ê¸ì •) / p('ì¢‹ë‹¤')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
