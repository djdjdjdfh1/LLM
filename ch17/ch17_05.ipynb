{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "개체명 인식 : NER\n",
        "  - 텍스트에서 특정 의미를 가진 단어나 구절을 찾아내고 분류하는 작업"
      ],
      "metadata": {
        "id": "SpBa1HsFJsq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 홍길동은 2025년 11월 19일 서울시청에서 삼성전자 직원을 만났다\n",
        "# 홍길동 - [인명]\n",
        "# 2024년 1월 15일 - [날짜]\n",
        "# 서울시청 - [지명]\n",
        "# 삼성전자 - [기관명]\n",
        "\n",
        "# 활용분야\n",
        "  # 뉴스기사 : 기사에서 인물, 장소, 기관 자동추출\n",
        "  # 의료문서 ; 병명, 약물명, 증상\n",
        "  # 계약서 : 회사명, 날짜, 금액\n",
        "  # 챗봇: 사용자 질문에 핵심정보 파악\n",
        "\n",
        "# BIO 태깅\n",
        "# B(Begin) 개체 시작\n",
        "# I(Inside) 개체 낸부\n",
        "# O(Outside) 개체가 아님\n",
        "\n"
      ],
      "metadata": {
        "id": "6SHfYXJ2JrhC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n"
      ],
      "metadata": {
        "id": "zxJlPP5BLlCv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BIO 태깅\n",
        "tokens = [\"김철수는\", \"2024년\", \"1월\", \"15일\", \"서울시청에서\", \"삼성전자\", \"직원을\", \"만났다\"]\n",
        "bio_tags = [\"B-PER\", \"B-DAT\", \"I-DAT\", \"I-DAT\", \"B-LOC\", \"B-ORG\", \"O\", \"O\"]\n",
        "for token, tag in zip(tokens, bio_tags):\n",
        "  if tag.startswith('B-'):\n",
        "    desc = f\"'{tag[2:]} 개체의 시작'\"\n",
        "  elif tag.startswith('I-'):\n",
        "    desc = f\"'{tag[2:]} 개체의 내부'\"\n",
        "  else:\n",
        "    desc = \"개체가 아님\"\n",
        "  print(f\"{token:12} | {tag:8} | {desc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em0Oa-hyMU0L",
        "outputId": "95bbfe8d-6bf8-4b2a-9ca0-efe1a3cb6a89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김철수는         | B-PER    | 'PER 개체의 시작'\n",
            "2024년        | B-DAT    | 'DAT 개체의 시작'\n",
            "1월           | I-DAT    | 'DAT 개체의 내부'\n",
            "15일          | I-DAT    | 'DAT 개체의 내부'\n",
            "서울시청에서       | B-LOC    | 'LOC 개체의 시작'\n",
            "삼성전자         | B-ORG    | 'ORG 개체의 시작'\n",
            "직원을          | O        | 개체가 아님\n",
            "만났다          | O        | 개체가 아님\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터\n",
        "train_sentences = [\n",
        "    [\"김철수는\", \"서울에\", \"산다\"],\n",
        "    [\"이영희는\", \"2024년에\", \"부산으로\", \"이사했다\"],\n",
        "    [\"삼성전자는\", \"대한민국의\", \"대기업이다\"],\n",
        "    [\"박지성은\", \"축구선수다\"],\n",
        "    [\"2025년\", \"1월\", \"1일은\", \"새해다\"],\n",
        "]\n",
        "\n",
        "train_labels = [\n",
        "    [\"B-PER\", \"B-LOC\", \"O\"],\n",
        "    [\"B-PER\", \"B-DAT\", \"B-LOC\", \"O\"],\n",
        "    [\"B-ORG\", \"B-LOC\", \"O\"],\n",
        "    [\"B-PER\", \"O\"],\n",
        "    [\"B-DAT\", \"I-DAT\", \"I-DAT\", \"O\"],\n",
        "]"
      ],
      "metadata": {
        "id": "DWmnws56NZMl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import mod\n",
        "# 토크나이져\n",
        "MODEL_NAME = 'skt/kobert-base-v1'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "text = '김철수는 서울에 산다'\n",
        "tokens = tokenizer.tokenize(text)\n",
        "encoded = tokenizer(text, return_tensors='pt')\n",
        "encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwEpHaVaN0JL",
        "outputId": "2327cd3a-23e2-45bc-d4bb-b92ab3939732"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[517, 490, 494,   0, 517,   0, 491,   0, 491,   0, 517,   0,   0,   0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NER 모델 3단계로 구성\n",
        "# 1. 입력 텍스트\n",
        "# 2. koBERT 인코더   문장의 의미를 이해\n",
        "# 3. 분류기(Linear)   예측\n",
        "# 4. 출력라벨        B-PER"
      ],
      "metadata": {
        "id": "nitFQuUVPHc0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class SimpleNERModel(nn.Module):\n",
        "  def __init__(self, num_labels) -> None:\n",
        "    super(SimpleNERModel, self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.bert = AutoModel.from_pretrained(MODEL_NAME)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.clf = nn.Linear(self.bert.config.hidden_size)\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    # kobert로 문자 인코딩\n",
        "    outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    # 마지막 은닉상태 추출\n",
        "    sequence_output = outputs.last_hidden_state\n",
        "    # Dropout 적용\n",
        "    self.dropout(sequence_output)\n",
        "    # 분류기\n",
        "    logits = self.clf(sequence_output)\n",
        "    return logits\n",
        "\n",
        "# 라벨의 수\n",
        "label_list = set([data for i in train_labels for data in i])\n",
        "label_list\n",
        "model = SimpleNERModel(num_labels = len(label_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "TckmeIREPtls",
        "outputId": "dfb9ba52-9ce6-475b-9996-603078d9c587"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Linear.__init__() missing 1 required positional argument: 'out_features'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2563124351.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleNERModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2563124351.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_labels)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# kobert로 문자 인코딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Linear.__init__() missing 1 required positional argument: 'out_features'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cyGKFudtRjaF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}