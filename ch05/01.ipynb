{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30df5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bow  Bag of Words  CountVectorizer\n",
    "# 문서를 고정된 길이의 벡터로 변환\n",
    "# 문서 - 단어행렬\n",
    "# 장점 : 간단하고 빠름\n",
    "# 단점 : 단어순서 손실, 희소성, 의미적 유사성 무시\n",
    "\n",
    "# tf-idf  TfidfVectorizer \n",
    "# 모든 문서에서 자주 등장하는 단어의 영향을 줄이고 문서의 특이 단어를 수집\n",
    "\n",
    "# multinomal Naive Bayes 확률 모델\n",
    "# LogisticRegression : 다중클래스  회귀기반 분류\n",
    "\n",
    "# RidgeClassifier : 회귀 기반 분류 L2규제(가중치 제곱의 값을 추가로 페널티 규제)\n",
    "\n",
    "# N-gram : 단점 차원 폭발에 주의 (정규화/차원 축소 고려)\n",
    "\n",
    "# Kolnpy Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f70136a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# scikit-learn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 분류모델\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcafed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "# data load\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                    remove=('headers', 'footers', 'quotes'),\n",
    "                    categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                    remove=('headers', 'footers', 'quotes'),\n",
    "                    categories=categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ee66e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 제거\n",
    "def filter_categories(dataset, categories):\n",
    "    target_names = dataset.target_names\n",
    "    selected_idx = [ target_names.index(c) for c in categories ]\n",
    "    # 필터링\n",
    "    data_filtered, target_filtered = [], []\n",
    "    for text, label in zip(dataset.data, dataset.target):\n",
    "        if label in selected_idx:\n",
    "            new_label = selected_idx.index(label)\n",
    "            data_filtered.append(text); target_filtered.append(new_label)\n",
    "    return data_filtered, target_filtered, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "526aa338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target, target_names = filter_categories(newsgroups_train, categories)\n",
    "test_data, test_target, _ = filter_categories(newsgroups_test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e76989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 헤더 푸터 인용문 제거\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # 헤더 제거\n",
    "    text = re.sub(r'^From:.\\n', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'^Subject:.\\n', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 풋터 제거\n",
    "    text = re.sub(r'\\n--\\n.$', '', text, flags=re.DOTALL)\n",
    "\n",
    "    # 인용문 제거\n",
    "    text = re.sub(r'(^|\\n)[>|:].', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7b61554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [ clean_text(t) for t in train_data ]\n",
    "test_data = [ clean_text(t) for t in test_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b2303e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 2034, 1353, 1353)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(train_target), len(test_data), len(test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924aeb70",
   "metadata": {},
   "source": [
    "- 멀티노멀 나이즈베이즈\n",
    "- 문서에 포함된 단어들의 출현 횟수를 기반으로 해서 그 문서가 어떤 주제에 속할지 확률적\n",
    "- 스팸필터링, 뉴스기사 카테고리, 감성분석\n",
    "\n",
    "- 베이즈정리 확률 이론 - 조건부 확률\n",
    "- 단어 A가 나왔을때, 이 문서가 스팸 B 일 확률은 얼마"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08173ea8",
   "metadata": {},
   "source": [
    "- 나이브 Naive : 순진한 가정\n",
    "    - 가정 : 문서안의 모든 단어는 서로 독립적\n",
    "    - 현실 : 스팸에 자주 나오는 단어들은 서로 독립적이지 않다\n",
    "    - 실제 : 이러한 가정은 계산량을 빠르게 하고 단순하지만 정확도가 어느정도 나온다\n",
    "- 멀티노멀 : 다항 분포\n",
    "    - 의미 : 단어의 출현 횟수를 중요\n",
    "    - 횟수를 세는 멀티노미얼 방식이 NLP 잘 맞는다\n",
    "    - 모델은 단어의 빈도수 통계\n",
    "    - 스팸메일 통계 spen\n",
    "        - free : 150\n",
    "        - money : 100\n",
    "        - viagra : 50\n",
    "        - report : 5\n",
    "    - 정상메일 Ham 통계\n",
    "        - report : 80\n",
    "        - meeting : 60\n",
    "        - free : 10\n",
    "    - 이러한 통계를 바탕으로 이 카테고리에서 특정 단어가 나올 확률 (P'free'|스펨) 을 모두 계산\n",
    "    - \"Free mondy meeting\"\n",
    "        - 스팸?\n",
    "            - 기본 스펨확률 x, 스펨일떄 free 가 나올 확률 x 스팸일떄 money 나올 확률 x 스팸일떄 meeting 나올 확률\n",
    "        - 정상\n",
    "            - 기본 정상확률 x 정상일떄..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
